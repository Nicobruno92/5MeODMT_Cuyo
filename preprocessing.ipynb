{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following script performs EEG data preprocessing through several steps:\n",
    "1. Read raw file\n",
    "2. Band pass filter 1 to 45hz\n",
    "3. Crop signal from tmin to tmax\n",
    "4. Visual inspection of channels. Drop bads\n",
    "5. Epochs of 2s (non-overlapping)\n",
    "6. Autoreject Epochs\n",
    "7. Manual inspection of Epochs\n",
    "8. ICA \n",
    "9. Interpolate bad channels\n",
    "10. Rereferenced to grand average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This magic command allows interactive plotting in a separate window\n",
    "%matplotlib qt\n",
    "\n",
    "# Import necessary libraries for the preprocessing\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mne\n",
    "\n",
    "# Importing libraries for automatic rejection of bad epochs\n",
    "from autoreject import AutoReject, get_rejection_threshold\n",
    "from pyprep import NoisyChannels\n",
    "\n",
    "\n",
    "# tag automatically ICA components\n",
    "# requires pytorch\n",
    "from mne_icalabel import label_components\n",
    "\n",
    "# Import helper functions for preprocessing\n",
    "import utils.preprocessing_helpers as preprocessing_helpers\n",
    "from utils.log_preprocessing import LogPreprocessingDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set subject and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Participant ID and condition being processed\n",
    "# participant ID  Ex: S02; S40\n",
    "id = '022'\n",
    "week = 1\n",
    "condition = 'baseline' #name of condition that it should be equal to the folder name\n",
    "\n",
    "# Filename of the raw EEG data\n",
    "# filename =  id_week.EDF\n",
    "filename = f\"{id}_{str(week)}.EDF\"\n",
    "\n",
    "\n",
    "##################################\n",
    "#########    FOLDERS    ##########\n",
    "##################################\n",
    "\n",
    "# Defining the paths for saving results and raw data\n",
    "root_path = 'results'\n",
    "raw_folder = 'raw'\n",
    "derivatives_folder = 'derivatives'\n",
    "save_folder = os.path.join(root_path, derivatives_folder, condition, id)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Initialize a report to document the preprocessing steps\n",
    "report = mne.Report(title=f'Preprocessing Subject {id}, for condition {condition} in week {week}', verbose = False)\n",
    "\n",
    "# Path to the JSON file where preprocessing details will be stored\n",
    "json_path = 'logs_preprocessing_details_all_subjects.json'\n",
    "\n",
    "# Initialize the logging class\n",
    "log_preprocessing = LogPreprocessingDetails(json_path, id, condition, week)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Raw EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "########   1.READ RAW   ##########\n",
    "##################################\n",
    "\n",
    "# Construct the full file path and read the raw EEG data file\n",
    "raw_file = os.path.join(root_path,  raw_folder, condition, str(id),filename)\n",
    "raw =   preprocessing_helpers.read_edf_akonic(raw_file)\n",
    "\n",
    "# Set the montage (electrode positions)\n",
    "raw = preprocessing_helpers.set_chs_montage(raw)\n",
    "\n",
    "print(raw.info)\n",
    "\n",
    "# Plot sensor location in the scalp\n",
    "# raw.plot_sensors(show_names=True)\n",
    "# plt.show()\n",
    "\n",
    "# Add the raw data info to the report\n",
    "report.add_raw(raw=raw, title='Raw', psd=True)\n",
    "\n",
    "# Log the raw data info\n",
    "log_preprocessing.log_detail('info', str(raw.info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notch filter to eliminate power line noise.\n",
    "raw_filtered = raw.copy().notch_filter(freqs=raw.info['line_freq'])\n",
    "\n",
    "# Apply a band-pass filter to keep frequencies between 1 and 45 Hz\n",
    "hpass = 1\n",
    "lpass = 45\n",
    "raw_filtered.filter(l_freq=hpass, h_freq=lpass)\n",
    "\n",
    "# Save the filtered data\n",
    "# raw_filtered.save(os.path.join(save_folder, f'{id}-filtered_eeg.fif'), overwrite=True)\n",
    "\n",
    "# Log the filter settings\n",
    "log_preprocessing.log_detail('hpass_filter', hpass)\n",
    "log_preprocessing.log_detail('lpass_filter', lpass)\n",
    "log_preprocessing.log_detail('filter_type', 'bandpass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visual inspection of Chs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots PSD of the filtered data\n",
    "raw_filtered.compute_psd().plot()\n",
    "\n",
    "#automatically mark bad channels\n",
    "nd = NoisyChannels(raw_filtered,do_detrend = False, random_state=42)\n",
    "nd.find_all_bads(ransac=True, channel_wise=True) #if it slows down, set channel_wise to False\n",
    "bads = nd.get_bads()\n",
    "print(f\"Bad channels detected: {bads}\")\n",
    "if bads != None:\n",
    "    raw_filtered.info[\"bads\"] = bads\n",
    "\n",
    "# Plot the filtered data for visual inspection to identify bad channels\n",
    "raw_filtered.plot(n_channels=32)\n",
    "plt.show(block=True)\n",
    "\n",
    "# Add the filtered data to the report\n",
    "report.add_raw(raw=raw_filtered, title='Filtered Raw', psd=True)\n",
    "\n",
    "# Log the identified bad channels\n",
    "log_preprocessing.log_detail('bad_channels', raw_filtered.info['bads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. EPOCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the continuous data into epochs of 2 seconds\n",
    "duration_epochs = 2.0\n",
    "epochs = mne.make_fixed_length_epochs(raw_filtered, duration=duration_epochs, preload=True, verbose=None)\n",
    "\n",
    "# Save the epoched data\n",
    "# epochs.save(os.path.join(save_folder, f'{id}-epoched_eeg.fif'), overwrite=True)\n",
    "\n",
    "# Add the epochs to the report\n",
    "report.add_epochs(epochs=epochs, title='Epochs')\n",
    "\n",
    "# Log the number of epochs and their duration\n",
    "log_preprocessing.log_detail('n_epochs', len(epochs))\n",
    "log_preprocessing.log_detail('duration_epochs', duration_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Rejectiion of bad epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "######    REJECT EPOCHS   ########\n",
    "##################################\n",
    "\n",
    "# Automatically reject bad epochs using AutoReject\n",
    "folds = 10  # Number of folds for cross-validation\n",
    "ar = AutoReject(thresh_method=\"bayesian_optimization\", cv = folds, random_state=42, n_jobs = -1, )\n",
    "epochs_clean = ar.fit_transform(epochs)\n",
    "reject = get_rejection_threshold(epochs)\n",
    "\n",
    "# Log the epochs rejected by AutoReject\n",
    "ar_reject_epochs = [n_epoch for n_epoch, log in enumerate(epochs_clean.drop_log) if log == ('AUTOREJECT',)] \n",
    "log_preprocessing.log_detail('autoreject_epochs', ar_reject_epochs)\n",
    "log_preprocessing.log_detail('autoreject_threshold', reject)\n",
    "log_preprocessing.log_detail('len_autoreject_epochs', len(ar_reject_epochs))\n",
    "#%%\n",
    "# epochs_clean = epochs # to skip autoreject  \n",
    "# ar_reject_epochs = [] # to skip autoreject  \n",
    "\n",
    "# Manually inspect and reject bad epochs\n",
    "epochs_clean.plot(scalings = 'auto')\n",
    "plt.show(block=True)\n",
    "\n",
    "# Log the epochs rejected manually\n",
    "manual_reject_epochs = [n_epoch for n_epoch, log in enumerate(epochs_clean.drop_log) if log == ('USER',)]\n",
    "print(f'Manually rejected epochs: {manual_reject_epochs}')\n",
    "total_epochs_rejected = (len(ar_reject_epochs) + len(manual_reject_epochs)) / len(epochs) * 100\n",
    "print(f'Total epochs rejected: {total_epochs_rejected}%')\n",
    "log_preprocessing.log_detail('manual_reject_epochs', manual_reject_epochs)\n",
    "log_preprocessing.log_detail('len_manual_reject_epochs', len(manual_reject_epochs))\n",
    "\n",
    "# Plot the drop log for further inspection\n",
    "epochs_clean.plot_drop_log()\n",
    "\n",
    "# Add the cleaned epochs to the report\n",
    "report.add_epochs(epochs=epochs_clean, title='Epochs clean', psd=False)\n",
    "\n",
    "# Save the cleaned epochs\n",
    "epochs_clean.drop_bad()\n",
    "# epochs_clean.save(os.path.join(save_folder, f'{id}-cleaned_epochs_eeg.fif'), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Independent Component Analysis (ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ICA (Independent Component Analysis) to remove artifacts\n",
    "n_components = 15  # Number of components to keep; typically should be higher, like 0.999\n",
    "method = 'picard'  # The algorithm to use for ICA # pip install python-picard\n",
    "max_iter = 512  # Maximum number of iterations; typically should be higher, like 500 or 1000\n",
    "random_state = 42  # Seed for random number generator for reproducibility\n",
    "\n",
    "# Initialize the ICA object with the specified parameters\n",
    "ica = mne.preprocessing.ICA(n_components=n_components, method=method, max_iter=max_iter, random_state=random_state)\n",
    "\n",
    "# Fit the ICA model to the cleaned epochs\n",
    "ica.fit(epochs_clean)\n",
    "\n",
    "# find EOG artifacts in the data via pattern matching, and exclude the EOG-related ICA components\n",
    "eog_components, eog_scores = ica.find_bads_eog(\n",
    "    inst=epochs_clean,\n",
    "    ch_name=\"Fp1\",  # a channel close to the eye\n",
    "    # threshold=1  # lower than the default threshold\n",
    ")\n",
    "print(f\"EOG components detected: {eog_components}\")\n",
    "\n",
    "# find ECG artifacts in the data via pattern matching, and exclude the ECG-related ICA components\n",
    "ecg_components, ecg_scores = ica.find_bads_ecg(\n",
    "    inst=epochs_clean,\n",
    "    ch_name=\"ECG\",  # a channel close to the eye\n",
    "    # threshold=1  # lower than the default threshold\n",
    ")\n",
    "print(f\"ECG components detected: {ecg_components}\")\n",
    "\n",
    "# find muscle artifacts in the data via pattern matching, and exclude the muscle-related ICA components\n",
    "muscle_components, muscle_scores = ica.find_bads_muscle(epochs_clean, threshold=0.7)\n",
    "print(f\"Muscle components detected: {muscle_components}\")\n",
    "# ica.plot_scores(muscle_scores, exclude=muscle_components)\n",
    "\n",
    "##### Classify the components using ICLabel model #######\n",
    "# run the model on the ICA components\n",
    "ic_labels = label_components(epochs_clean, ica, method=\"iclabel\")\n",
    "# print labels of each component\n",
    "print(\"Classification of all ICA components. Results:\")\n",
    "print(ic_labels[\"labels\"])\n",
    "\n",
    "# Extract ICA component labels\n",
    "label_names = ic_labels['labels']\n",
    "# Combine all artifact components from the pattern matching methods\n",
    "pattern_matching_artifacts = np.unique(ecg_components + eog_components + muscle_components)\n",
    "\n",
    "# Identify the ICA components that correspond to a 'channel noise' in ICLabel\n",
    "channel_artifact_indices = [i for i, label in enumerate(label_names) if label == 'channel noise']\n",
    "\n",
    "# Find components that coincide between pattern matching and ICLabel output for exclusion\n",
    "# We'll only exclude components that match the artifacts found via pattern matching \n",
    "# and are classified as 'muscle artifact', 'eye blink', 'heart beat', or 'channel noise'\n",
    "to_exclude = []\n",
    "for idx in pattern_matching_artifacts:\n",
    "    if label_names[idx] in ['muscle artifact', 'eye blink', 'heart beat', 'channel noise']:\n",
    "        to_exclude.append(idx)\n",
    "\n",
    "# Also ensure to include 'channel noise' components that were found only by ICLabel\n",
    "to_exclude = np.unique(to_exclude + channel_artifact_indices)\n",
    "\n",
    "# Exclude the selected components\n",
    "ica.exclude = to_exclude.tolist()\n",
    "\n",
    "# (Optional) Plot the ICA components for visual inspection\n",
    "# ica.plot_components(inst=epochs_clean, picks=range(15))\n",
    "\n",
    "# Plot the sources identified by ICA\n",
    "ica.plot_sources(epochs_clean, block=True, show=True)\n",
    "plt.show(block=True)\n",
    "\n",
    "# Add the ICA results to the report\n",
    "report.add_ica(ica, title='ICA', inst=epochs_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FINAL EPOCH CLEANING #######\n",
    "# baseline = (-0.3, 0)  # to be done after ICA\n",
    "# epochs_ica.apply_baseline(baseline)\n",
    "# log_preprocessing.log_detail(\"baseline\", baseline)\n",
    "\n",
    "# Apply the ICA solution to the cleaned epochs\n",
    "epochs_ica = ica.apply(inst=epochs_clean)\n",
    "\n",
    "# Log the ICA parameters and excluded components\n",
    "log_preprocessing.log_detail('ica_components', ica.exclude)\n",
    "log_preprocessing.log_detail('ica_method', method)\n",
    "log_preprocessing.log_detail('ica_max_iter', max_iter)\n",
    "log_preprocessing.log_detail('ica_random_state', random_state)\n",
    "\n",
    "# Manually inspect the epochs after ICA application\n",
    "epochs_ica.plot(scalings = 'auto')\n",
    "plt.show(block=True)\n",
    "\n",
    "# Log manually rejected epochs after ICA\n",
    "all_manual_epochs = [n_epoch for n_epoch, log in enumerate(epochs_ica.drop_log) if log == ('USER',)]\n",
    "manual_reject_epochs_after_ica = [n_epoch for n_epoch in all_manual_epochs if n_epoch not in manual_reject_epochs]\n",
    "print(f'Manually rejected epochs after ICA: {manual_reject_epochs_after_ica}')\n",
    "total_epochs_rejected = (len(ar_reject_epochs) + len(manual_reject_epochs) + len(manual_reject_epochs_after_ica)) / len(epochs) * 100\n",
    "print(f'Total epochs rejected: {total_epochs_rejected}%')\n",
    "log_preprocessing.log_detail('manual_reject_epochs_after_ica', manual_reject_epochs_after_ica)\n",
    "log_preprocessing.log_detail('len_manual_reject_epochs_after_ica', len(manual_reject_epochs_after_ica))\n",
    "log_preprocessing.log_detail('total_epochs_rejected', total_epochs_rejected)\n",
    "log_preprocessing.log_detail('epochs_drop_log', epochs_ica.drop_log)\n",
    "log_preprocessing.log_detail('epochs_drop_log_description', epochs_ica.drop_log)\n",
    "\n",
    "# Save the epochs after ICA application and drop epochs\n",
    "# epochs_ica.save(os.path.join(save_folder, f'{id}-ica_eeg.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Interpolate bad Chs and Rereference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate and Rereference chs\n",
    "##################################\n",
    "######   Interpolate chs  ########\n",
    "##################################\n",
    "# Interpolate bad channels in the epochs after ICA application\n",
    "epochs_interpolate = epochs_ica.copy().interpolate_bads()\n",
    "\n",
    "# Log the interpolated channels\n",
    "log_preprocessing.log_detail('interpolated_channels', epochs_ica.info['bads'])\n",
    "\n",
    "##################################\n",
    "#######    Rereference   #########\n",
    "##################################\n",
    "# Rereference the data to the grand average reference\n",
    "epochs_rereferenced, ref_data = mne.set_eeg_reference(inst=epochs_interpolate, ref_channels='average', copy=True)\n",
    "\n",
    "# Save the rereferenced epochs\n",
    "epochs_rereferenced.save(os.path.join(save_folder, f'{id}-rereferenced_eeg.fif'), overwrite=True)\n",
    "\n",
    "# Add the final epochs to the report\n",
    "report.add_epochs(epochs=epochs_rereferenced, title='Epochs interpolated and rereferenced', psd=True)\n",
    "\n",
    "# Log the rereferencing details\n",
    "log_preprocessing.log_detail('rereference', 'grand_average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. CROP signal into Baseline and Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "########        CROP signal into Baseline and Active        ########\n",
    "####################################################################\n",
    "# Define the variables for the baseline and dosis times\n",
    "t_min_baseline = 60  # Start time of the baseline in seconds\n",
    "t_max_baseline = t_min_baseline + 5 * 60  # End time of the baseline in seconds\n",
    "t_0_dosis = 700  # Start time of the dosis in seconds\n",
    "t_max_dosis = t_0_dosis + 18 * 60  # End time of the dosis in seconds\n",
    "\n",
    "# Calculate the epoch indices for baseline and dosis\n",
    "# Since each epoch is 2 seconds, divide the times by 2 to get the epoch indices\n",
    "idx_start_baseline = int(t_min_baseline / 2)\n",
    "idx_end_baseline = int(t_max_baseline / 2)\n",
    "idx_start_dosis = int(t_0_dosis / 2)\n",
    "idx_end_dosis = int(t_max_dosis / 2)\n",
    "\n",
    "# Select epochs by indices\n",
    "epochs_baseline = epochs_rereferenced[idx_start_baseline:idx_end_baseline]\n",
    "epochs_dosis = epochs_rereferenced[idx_start_dosis:idx_end_dosis]\n",
    "\n",
    "epochs_baseline.save(os.path.join(save_folder, f'{id}-baseline-prepro_eeg.fif'), overwrite=True)\n",
    "epochs_dosis.save(os.path.join(save_folder, f'{id}-dosis-prepro_eeg.fif'), overwrite=True)\n",
    "\n",
    "# Log the preprocessing details\n",
    "log_preprocessing.log_detail('t_min_baseline', t_min_baseline)\n",
    "log_preprocessing.log_detail('t_max_baseline', t_max_baseline)\n",
    "log_preprocessing.log_detail('t_0_dosis', t_0_dosis)\n",
    "log_preprocessing.log_detail('t_max_dosis', t_max_dosis)\n",
    "\n",
    "\n",
    "# Save the report as an HTML file\n",
    "report.save(os.path.join(save_folder, f'{id}-report.html'), overwrite=True)\n",
    "\n",
    "# Save the preprocessing details to the JSON file\n",
    "log_preprocessing.save_preprocessing_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Observed Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_baseline.plot()\n",
    "plt.show(block=True)\n",
    "\n",
    "epochs_dosis.plot()\n",
    "plt.show(block=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
